#!/bin/bash

#######################################################################
#                                              
# Description 
# -----------
#
# This script allow you to copy crab outputs located on DPM. It assumes 
# that when running crab, you put in "user_remote_dir" something of the
# form :                                
#                                            
#   user_remote_dir=prodName/taskName         
#                                            
# and that your outputs are not located in a folder such as :                           
#                                            
#   $DPM/yourName/prodName/taskName           
#                                            
# and you want to copy locally all the files in that folder starting by 
# $TARGET.        
#                                            
# This script will create a folder 'taskName' in the current directory, 
# copying all the files matching ${TARGET}_*.root, BUT will ignore :
#
#  * those that are already in the local folder and have the same size  
#    as the remote file (allows to restart the script if it crashes, for
#    instance because of expired proxy)                                 
#  
#  * the duplicate files, ie the one with same crab job Id, but that are
#    not the newest one (ie probably failed jobs). The script will copy 
#    the newest version but ignore the older ones.                      
#            
#
#
# Usage
# -----
#
# * define PRODNAME and TARGET as you need 
#
# * type :
#             ./harvestProdOnDPM taskName
#
# * get coffee
#
#######################################################################

###########################
# Configuration variables #
###########################

PRODNAME=July13-v1
TARGET=NTuple
TASKNAME=$1

LOCAL_PWD=$PWD
DPM=/dpm/in2p3.fr/home/cms/phedex/store/user
CRAB_HOME=${DPM}/${USER}/${PRODNAME}


################################################################
# Create local folder and get list of content on remote folder #
################################################################

mkdir -p $TASKNAME
rm -f $TASKNAME/toBeHarvested.list

rfdir $CRAB_HOME/$TASKNAME/ | grep ${TARGET} > $TASKNAME/rawDump
RAWLIST=`cat $TASKNAME/rawDump | awk '{ print $9 }'`


########################################################
# Parse the content to list what needs to be harvested #
########################################################

# For each file in the list...
for FILE in $RAWLIST
do
    
    # Read the corresponding job number
    JOBNUMBER=`echo $FILE | sed 's|_| |g' | awk '{print $2}'`
       
    # Check that the file doesn't exist locally yet
    CHECK_SYNC=false
    if [[ -f $TASKNAME/$FILE ]]
    then
        # If it does exist locally, check that the size is the same as the remote file
        SIZE_FILE_ON_CRAB=`cat $TASKNAME/rawDump | grep $FILE | awk '{ print $5 }'`
        SIZE_FILE_LOCAL=`ls -l $TASKNAME/$FILE | awk '{print $5}'`
        if [[ $SIZE_FILE_ON_CRAB == $SIZE_FILE_LOCAL ]]
        then
            CHECK_SYNC=false
        else
            CHECK_SYNC=true
        fi
    else
        CHECK_SYNC=true
    fi

    # List all the files that have the same job number as this one
    OCCURENCES=`cat $TASKNAME/rawDump | awk '{print $9}' | grep ${TARGET}_${JOBNUMBER}_`
    # Count how many there are
    NOCCURENCES=`echo $OCCURENCES | wc -w`
    CHECK_DUPLIC=true

    # If there is at least two files with same job number
    if [[ $NOCCURENCES -ge 2 ]]
    then
        
        # Find the most recent one by looking at the date
        OCC_MOSTRECENT=""
        DATEINSEC_MOSTRECENT=0
        for OCC in $OCCURENCES
        do
            # God, this script is dirty
            DATE=`cat $TASKNAME/rawDump | grep $OCC | awk '{print $6 " " $7 " " $8}'`
            DATEINSEC=`date -d "$DATE" +'%s'`
            if [[ $DATEINSEC -gt $DATEINSEC_MOSTRECENT ]]
            then
                OCC_MOSTRECENT=$OCC
                DATEINSEC_MOSTRECENT=$DATEINSEC
            fi
        done
        
        # Check if the file we have now is the most recent occurence
        if [[ $FILE == $OCC_MOSTRECENT ]]
        then
            CHECK_DUPLIC=true
        else
            CHECK_DUPLIC=false
        fi
    
    fi

    # If we need to sync, and if this file
    # is the most recent ones among all the files with same job number...
    if [[ $CHECK_SYNC == true  ]]
    then
    if [[ $CHECK_DUPLIC == true  ]]
    then
        # Then add it to the files to be harvested
        echo $FILE >> $TASKNAME/toBeHarvested.list
    fi
    fi

done
    
rm -f $TASKNAME/rawDump

##########################################################
# Perform an rfcp on each file that need to be harvested #
##########################################################

rm -f $TASKNAME/log

for FILE in `cat $TASKNAME/toBeHarvested.list`
do
    echo "$TASKNAME :: Copying $FILE ... " >> $TASKNAME/log
    rfcp $CRAB_HOME/$TASKNAME/$FILE ./$TASKNAME/
done


